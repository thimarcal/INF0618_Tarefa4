{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 04 - Verificação Facial com Redes Siamesas\n",
    "\n",
    "Nesta tarefa, você irá construir e treinar uma rede siamesa para o problema de verificação facial. A rede irá receber um par de imagens e deverá dizer se elas foram tiradas da mesma pessoa ou de pessoas diferentes. Para isso, pedimos que você defina o modelo da sua arquitetura siamesa, carregue os dados, treine a rede e avalie sua performance no conjunto de teste.\n",
    "\n",
    "------------\n",
    "## IMPORTANTE\n",
    "##### Verifique os pontos abaixo antes de começar a tarefa:\n",
    "- Faça o download dos dados em https://goo.gl/yoEBsF e descomprima na mesma pasta deste notebook.\n",
    "- Verifique se a pasta `INF0618-Tarefa04-faces` está no mesmo diretório deste notebook. Ela deverá conter as pastas `train`, `test`, `val` e também os arquivos `train_pairs.txt`, `test_pairs.txt` e `val_pairs.txt`. \n",
    "- Não há necessidade de alterar os códigos das sessões `Imports` e `Dataset`.\n",
    "-----------\n",
    "\n",
    "\n",
    "As tarefas são:\n",
    "\n",
    "**1) Definição da arquitetura [0.3 pts]**\n",
    "- Defina a arquitetura base que será utilizada em cada branch da rede siamesa;\n",
    "- Defina os inputs e conecte-os a arquitetura base;\n",
    "- Calcule a distância euclideana dos outputs de cada branch;\n",
    "\n",
    "**2) Treinamento [0.3 pts]**\n",
    "- Compile o seu modelo, definindo a contrastive loss e qual o otimizador que será utilizado;\n",
    "- Defina também número de batches e número de épocas;\n",
    "- Treine para obter a maior acurácia que vocês conseguirem;\n",
    "\n",
    "**3) Teste [0.15 pts]**\n",
    "- Avalie o conjunto de teste e reporte a loss e a acurácia normalizada;\n",
    "\n",
    "**4) Conclusões [0.25 pts]**\n",
    "- Escreva um parágrafo resumindo o que você fez, as dificuldades que encontrou, o que deu certo/errado e as suas conclusões desta atividade.\n",
    "\n",
    "------\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "#Add other imports that you might need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "O dataset é composto de imagens de faces em diversas condições de iluminação e expressões faciais. As imagens foram centralizadas em relação às posições dos olhos. As identidades foram divididas de forma disjunta entre os conjuntos treino/validação/teste, que contam com 37/22/8 indivíduos com número variado de imagens por identidade.\n",
    "\n",
    "Dentro de cada conjunto, criamos todas as combinações de pares da mesma identidade (classe positiva) e limitamos a quantidade de pares de identidades diferentes (classe negativa) por este número. Dessa forma, cada conjunto está balanceado nas classes.\n",
    "\n",
    "** IMPORTANTE NÃO ALTERAR O NOME/LOCAL DAS IMAGENS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDir = \"./INF0618-Tarefa04-faces\"\n",
    "trainPairFile = datasetDir + \"/train_pairs.txt\"\n",
    "valPairFile = datasetDir + \"/val_pairs.txt\"\n",
    "testPairFile = datasetDir + \"/test_pairs.txt\"\n",
    "\n",
    "input_shape = (112,112,3)\n",
    "\n",
    "def preProcessPair(line):\n",
    "    img1Path, img2Path, label = line.strip().split(\"\\t\")\n",
    "\n",
    "    img1 = img_to_array(load_img(img1Path, target_size=input_shape))\n",
    "    img1 = img1.astype('float32')\n",
    "    img1 /= 255.0\n",
    "\n",
    "    img2 = img_to_array(load_img(img2Path, target_size=input_shape))\n",
    "    img2 = img2.astype('float32')\n",
    "    img2 /= 255.0\n",
    "    \n",
    "    label = int(label)\n",
    "    \n",
    "    return img1, img2, label\n",
    "    \n",
    "#Read our dataset in batches\n",
    "def loadDatasetInBatches(pairFile = trainPairFile, batch_size=32, shouldAugmentData=False):\n",
    "\n",
    "    ######### If you want to run with Data Augmentation, just uncomment here and some lines bellow\n",
    "    ##### you can add more transformations (see https://keras.io/preprocessing/image/)\n",
    "    #if shouldAugmentData == True:\n",
    "        #dataAugmentator = ImageDataGenerator(...)\n",
    "    \n",
    "\n",
    "    with open(pairFile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    while True:\n",
    "        shuffledLines = sample(lines, len(lines)) #shuffle images in each epoch\n",
    "        \n",
    "        leftBatch, rightBatch, labelList = [], [], []\n",
    "        nInBatch = 0\n",
    "        \n",
    "        #loop of one epoch\n",
    "        for idx in list(range(len(shuffledLines))):\n",
    "                        img1, img2, label = preProcessPair(shuffledLines[idx])\n",
    "    \n",
    "                        ### We apply a random transformation and add this image (instead of the original)\n",
    "                        ### to the batch...\n",
    "                        #if shouldAugmentData == True:\n",
    "                            #img1 = dataAugmentator.random_transform(img1)\n",
    "                            #img2 = dataAugmentator.random_transform(img2)\n",
    "    \n",
    "                        leftBatch.append(img1)\n",
    "                        rightBatch.append(img2)\n",
    "                        labelList.append(label)\n",
    "                        nInBatch += 1\n",
    "                        \n",
    "                        #if we already have one batch, yields it\n",
    "                        if nInBatch >= batch_size:\n",
    "                            yield [np.array(leftBatch),np.array(rightBatch)], np.array(labelList)\n",
    "                            leftBatch, rightBatch, labelList = [], [], []\n",
    "                            nInBatch = 0\n",
    "\n",
    "        #yield the remaining of the batch\n",
    "        if nInBatch > 0:\n",
    "            yield [np.array(leftBatch),np.array(rightBatch)], np.array(labelList)\n",
    "\n",
    "def getDatasetSize(pairFile):\n",
    "    with open(pairFile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return len(lines)\n",
    "\n",
    "               \n",
    "def plotPair(img1, img2):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.imshow(np.uint8(img1.reshape(input_shape)*255.0), interpolation='nearest')\n",
    "    \n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.imshow(np.uint8(img2.reshape(input_shape)*255.0), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "trainSetSize = getDatasetSize(trainPairFile)\n",
    "valSetSize = getDatasetSize(valPairFile)\n",
    "testSetSize = getDatasetSize(testPairFile)\n",
    "\n",
    "print(\"# pairs in Train set: \", trainSetSize)\n",
    "print(\"# pairs in Val set: \", valSetSize)\n",
    "print(\"# pairs in Test set: \", testSetSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, labels in loadDatasetInBatches(trainPairFile, batch_size=5):\n",
    "    idx = 0\n",
    "    leftBatch, rightBatch = batch\n",
    "    for idx in list(range(leftBatch.shape[0])):\n",
    "        print(\"Image1 size: \", leftBatch[idx].shape, \"\\t\", \"Image2 size: \", rightBatch[idx].shape,\"\\t Label:\", labels[idx])\n",
    "        plotPair(leftBatch[idx], rightBatch[idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o load do dados é feito...  \n",
    "De forma parecida com o que foi feito na Tarefa03, iremos utilizar o método `loadDatasetInBatches(pairFile = trainPairFile, batch_size=32)`. Ele é um generator, ou seja, ele gera um fluxo de batches e labels a partir do nosso dataset.\n",
    "\n",
    "**Argumentos**:\n",
    "- (string) **pairFile**: se refere a qual conjunto de dados que iremos ler (treino, validação ou teste). Recebe um dos arquivos de pares definido anteriormente (trainPairFile, valPairFile, testPairFile);\n",
    "- (int) **batch_size**: quantos pares por batch;\n",
    "\n",
    "**Retorno**: \n",
    "- **batch**: retorna uma lista com 2 arrays numpy (um contendo todas as 1as imagens de cada par e outro contendo as 2as imagens de cada par). **batch** é uma lista de tamanho 2 e cada posição é array numpy com dimensões `(batch_size, 112, 112, 3)` pois são **batch_size** imagens com tamanho 112x112 e 3 canais (RGB);\n",
    "- **labels**: retorna um array do numpy com as labels (1 para \"mesma identidade\" e 0 p/ \"identidades diferentes\");\n",
    "    \n",
    "Utilizando o argumento `pairFile`, o método lê as linhas do arquivo de pares e as embaralha (para garantir que a cada época os batches sejam diferentes). Para cada época (um loop do `for` interno), o método irá carregar um par por vez carregar e pre-processas ambas imagens. A primeira imagem do par será guardada em `leftBatch`, a segunda em `rightBatch` e a label em `labelList`.\n",
    "\n",
    "Quando estas listas estiverem com **batch_size** elementos, teremos gerado um batch. O método dá um yield nas lista [`leftBatch`, `rightBatch`] e na `labelList` e recomeça a construção de um novo batch. Quando o `for` terminar, iremos ter completado uma época. O `while True` apenas garante uma nova época seja iniciada. Quem controlará o fim do `while` vai ser o método que fará o fit, portanto não precisamos nos preocupar com isso.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "** -----> A tarefa começa aqui !!! Vocês não precisam modificar nada dos códigos acima!** \n",
    "\n",
    "# Definição da arquitetura siamesa [0.3 pts]\n",
    "- Defina a arquitetura base que será utilizada em cada branch da rede siamesa;\n",
    "- Defina os inputs e conecte-os a arquitetura base;\n",
    "- Calcule a distância euclideana dos outputs de cada branch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defina sua arquitetura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento [0.3 pts]\n",
    "- Compile o seu modelo, definindo a contrastive loss e qual o otimizador que será utilizado;\n",
    "- Defina também número de batches e número de épocas;\n",
    "- Treine para obter a maior acurácia que vocês conseguirem;\n",
    "\n",
    "Da mesma forma que na Tarefa03, iremos utilizar o `fit_generator` para otimizar nossa rede. Ele recebe um generator (que será fornecido pelo `loadDatasetInBatches`). Como o generator retorna um fluxo de batches/labels, o `fit_generator` não tem informação sobre o tamanho dataset. Por isso, precisamos informar o número de épocas (parâmetro `epochs`) e também quantos batches compõe uma época (parâmetro `steps_per_epoch`). Ao total, teremos 2 generators, um para o conjunto de treino e outro para o conjunto de validação.\n",
    "\n",
    "Para mais informações sobre o fit_generator e seus parâmetros, [acesse a documentação do Keras](https://keras.io/models/sequential/#fit_generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile o modelo / Defina a loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir tamanho do batch e número de épocas\n",
    "batch_size = \n",
    "epochs = \n",
    "\n",
    "#Criação dos generators\n",
    "# IMPORTANTE ---> Se for utilizar data augmentation, passe a flag shouldAugmentData como True no treinamento\n",
    "trainGenerator = loadDatasetInBatches(trainPairFile, batch_size = batch_size) #shouldAugmentData = True\n",
    "valGenerator = loadDatasetInBatches(valPairFile, batch_size = batch_size) #shouldAugmentData = False\n",
    "\n",
    "#Fit nos dados\n",
    "model.fit_generator(trainGenerator, \n",
    "                    steps_per_epoch= int(trainSetSize / batch_size), \n",
    "                    epochs = epochs,\n",
    "                    validation_data = valGenerator,  \n",
    "                    validation_steps = int(valSetSize / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste [0.15 pts]\n",
    "O teste será feito da mesma forma, utilizando `loadDatasetInBatches` para o conjunto de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do generator p/ o conjunto de teste\n",
    "testGenerator = loadDatasetInBatches(testPairFile, batch_size=batch_size)\n",
    "\n",
    "#Teste\n",
    "metrics = model.evaluate_generator(testGenerator, \n",
    "                                   steps=int(testSetSize/batch_size), \n",
    "                                   verbose=1)\n",
    "\n",
    "print(\"Test Loss ---> \", metrics[0])\n",
    "print(\"Test Accuracy ---> \", metrics[1])    #Test is balanced, so Acc is normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões  [0.25 pts]\n",
    "Escreva um parágrafo com as conclusões que você tirou na tarefa. Comente as dificuldades encontradas, as tentativas feitas, como foi o seu treinamento, apontando a motivação pelas decisões tomadas. Se o resultado ficou melhor/pior do que o que você esperava, o que você acha que pode ter acontecido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
